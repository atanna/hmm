\documentclass{matmex-diploma-custom}

\begin{document}
% Год, город, название университета и факультета предопределены,
% но можно и поменять.
% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
\filltitle{ru}{
 university = {Правительство Российской Федерации\\Федеральное государственное бюджетное образовательное учреждение высшего профессионального образования\\
«Санкт-Петербургский государственный университет»},
	faculty = {\hfill},
    chair              = {Кафедра Системного Программирования},
    title              = {Скрытые Марковские модели переменного порядка для анализа
данных ChIP-seq},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    type               = {bachelor},
    position           = {студента},
    group              = 444,
    author             = {Атаманова Анна Михайловна},
    supervisorPosition = {д.\,ф.-м.\,н., профессор},
    supervisor         = {Терехов А.\,Н.},
    reviewerPosition   = {},
    reviewer           = {Тузова Е.\,А.},
    chairHeadPosition  = {д.\,ф.-м.\,н., профессор},
    chairHead          = {Терехов А.\,Н.},
%   university         = {Санкт-Петербургский Государственный Университет},
%   faculty            = {Математико-механический факультет},
%    city               = {Санкт-Петербург},
%   year               = {2015}
}
\filltitle{en}{
	type 			  = {bachelor},
	faculty 			  = {\hfill},
    chair              = {Chair of Software Engineering},
    title              = {Variable-length hidden Markov models for ChIP-seq data analysis},
    author             = {Anna Atamanova},
    supervisorPosition = {professor},
    supervisor         = {Andrey Terekhov},
    reviewerPosition   = {},
    reviewer           = {Ekaterina Tuzova},
    chairHeadPosition  = {professor},
    chairHead          = {Andrey Terekhov},
}
\maketitle
\tableofcontents
% У введения нет номера главы
\section*{Введение}
\subsection*{Предметная область}
Дезоксирибонуклеиновая кислота (ДНК) --- молекула, обеспечивающая хранение генетического кода, который определяет развитие и функционирование живых организмов. ДНК хранит наследственную информацию, информацию о структуре РНК и белков. Белки выполняют структурные, сигнальные, механические и другие функции. Соединения ДНК с конкретным белком могут влиять на конформацию ДНК, на внутренние механизмы управления клетки, поэтому изучение ДНК-белковых взаимодействий крайне важно и актуально.

Геном --- это совокупность всех молекул ДНК в клетке.
Каждая ДНК состоит из двух цепей нуклеотидов, поэтому длина генома измеряется в парах нуклеотидов (пн).

В данной работе рассматривается задача нахождения позиций связывания ДНК и конкретного белка, то есть нахождения позиций ДНК-белковых взаимодействий при заранее выбранном белке. 

\subsection*{ChIP-seq}
ChIP-seq (иммунопреципитация хроматина с последующим секвенированием, англ. chromatin immunoprecipitation sequencing) --- биологический эксперимент, позволяющий получить информацию о наличии или отсутствии
взаимодействия ДНК с заданным белком.

Эксперимент проводится на множестве одинаковых клеток и включает в себя следующие стадии:
\begin{enumerate}
\item фиксация всех обнаруженных белков на ДНК;
\item расщепление ДНК на фрагменты;
\item вылавливание фрагментов, связанных с исследуемым белком (с помощью специфичного к исследуемому белку антитела);
\item считывание концов фрагментов (называемых ридами или прочтениями) до тех пор, пока каждый фрагмент с высокой вероятностью не будет прочитан несколько раз.
\end{enumerate} 

Далее для каждого полученного рида ищется соответствующий
ему участок последовательности генома (рис.~\ref{fig:chip-seq}). Обычно
риды, которым может соответствовать более одного участка в геноме,
исключают из рассмотрения.

\begin{figure}[h]
  \centering

\begin{Verbatim}[commandchars=\\\{\}]
          CAAAAGACAAATAGTGATGTCACCAATCGAGC
          --------------------------------
               GACA ATA     GTCA  AATC
              AGAC   TAGTG TGTC
               GACA   AGTG TGTCA   ATCG

          00001100001110000110000011000000
\end{Verbatim}
  \caption{Схематичное изображение выравнивания прочтений секвенатора (под чертой)
    на известную последовательность генома (над чертой).}
  \label{fig:chip-seq}
\end{figure}

Результаты эксперимента представляют в виде массива длины генома, в позиции которого стоит 1, если в соответствующей позиции генома начиналось хотя бы одно прочтение
и 0 в обратном случае.

Соединение белка с ДНК происходит не точечно, а на некотором участке ДНК, поэтому, для дальнейшего анализа, полученный массив разбивается на отрезки заранее выбранной длины, называемые окнами (обычно 200 пн). Значение в окне определяется как сумма единиц в нем. 

Эксперимент ChIP-seq (как и большинство биологических
экспериментов) не исключает наличие ошибок в результатах. Недостаточная специфичность антитела, наличие ошибок секвенирования, нестабильность положения белка на ДНК приводят к возникновению сигнала, не
зависящего от наличия взаимосвязи.
Поэтому, для дальнейшего анализа результатов эксперимента, требуется построение вероятностной модели, способной отделять ошибки, а также 
выявлять зависимости соединений и, по возможности, описывать их структуру.

Большинство существующих моделей (\cite{Zhang2008}, \cite{Spyrou2009}) для данных
ChIP-seq основано на аппарате скрытых Марковских моделей (СММ) 
первого порядка \cite{Rabiner1989} с Пуассоновскими испусканиями. Использование распределения
Пуассона для моделирования покрытия опирается на предположение о том, что в каждой
позиции генома в среднем начинается одинаковое количество прочтений.
Марковский процесс, как правило, имеет два состояния <<$1$>> --- сигнал есть и <<$0$>> --- сигнала нет. Первый порядок модели означает, что состояние некоторого окна зависит только от состояния его прямого предшественника.
Использование моделей первого порядка объясняется тем, что количество параметров
модели, а также сложность её обучения и использования экспоненциально зависят от
порядка. Так, СММ порядка $ m $ для каждой цепочки из $ m $ состояний содержит распределение на следующее состояние ($ 2^m $ вероятностных распределений). В связи с этим, неправильный выбор $ m $ при обучении сильно усложняет модель и способствует ее переобучению. Переобучение --- это одна из основных проблем машинного обучения, при которой модель слишком сильно подгоняется под обучающую выборку и находит в ней случайные закономерности, которые не характерны для данных генеральной совокупности.

Скрытые Марковские модели переменного порядка менее склонны к переобучению в силу того, что они не фиксируют длину строки, порождающей следующее состояние, и стараются ее уменьшить.

\section{Постановка задачи}
Целью данной дипломной работы является построение скрытой Марковской модели переменного
порядка для анализа данных ChIP-seq.

Для достижения цели были определены следующие задачи:
\begin{enumerate}
\item
реализовать скрытую Марковскую модель
переменного порядка;
\item
проанализировать 
эффективность работы модели на синтетических
данных;
\item
применить к данным ChIP-seq, сравнить с более простыми моделями (СММ
первого порядка).
\end{enumerate}


\section{Обзор существующих решений}
Марковские модели переменного порядка (не скрытые) обучаются путем построения контекстного дерева переходов \cite{Buhlmann1999}. Скрытые Марковские модели фиксированного порядка обучаемы алгоритмом Баума-Велша \cite{Rabiner1989}.
В работе \cite{Wang2006} было предложено совмещение этих двух идей для обучения скрытых Марковских моделей переменного порядка (СММПП).

В данной работе алгоритмом обучения СММПП был выбран модифицированный под поставленную задачу алгоритм  из \cite{Wang2006}. 
Модификация заключается в следующем: наблюдения итоговой модели будут порождаться из соответствующих состояний, т.е. распределение значений для каждого окна задается скрытым состоянием, которое определяет, была ли там взаимосвязь с белком или нет. В работе \cite{Wang2006} такие распределения определялись всем контекстом. 
Алгоритм был дополнен недостающей информацией об обучении контекстных деревьев из статей \cite{Buhlmann1999}, \cite{Dumont2014}.

\subsection{Основные понятия и определения}

Путь 
$ S = \{0, 1\} $ --- множество состояний (в рамках рассматриваемой задачи, <<$1$>> означает наличие связи, <<$0$>>--- ее отсутствие), 
$X_0, X_1, \ldots $ --- последовательность случайных величин (дискретный случайный процесс), значения которых лежат в S, а
$x_0, x_1, \ldots$ --- некоторая реализация случайных величин $X_0, X_1, \ldots $.

\begin{definition} $ \{X_{i}\}_{i \in Z_{+}}$ называется \emph{Марковским процессом порядка $ m $}, если  
\begin{align}
&\forall t, t'\in N, \;t, t' \geq m,\; \forall \overrightarrow{x} \in S^{t+1}\nonumber
\\&P(X_{t} = x_{t}|X_{t-1}=x_{t-1},X_{t-2}=x_{t-2}, \ldots ,X_{0}=x_{0}) \nonumber
\\&=P(X_{t} = x_{t}|X_{t-1}=x_{t-1},X_{t-2}=x_{t-2}, \ldots ,X_{t-m}=x_{t-m})\nonumber
\\&=P(X_{t'} = x_{t}|X_{t'-1}=x_{t-1},X_{t'-2}=x_{t-2}, \ldots ,X_{t'-m}=x_{t-m})\nonumber
\\&=P(X_{t'} = x_{t}|X_{t'-1}=x_{t-1},X_{t'-2}=x_{t-2}, \ldots ,X_{0}=x_{0}) 
\end{align}
\label{MP}
\end{definition}
Далее, для Марковских процессов, вероятности вида  
$$P(X_{t'} = x_{t}|X_{t'-1}=x_{t-1},X_{t'-2}=x_{t-2}, \ldots ,X_{t'-m}=x_{t-m})$$ где $t'\geq m$, 
будем записывать как $P(x_{t} |x_{t-1}\ldots x_{t-m})$. Запись корректна, в силу независимости такой вероятности от $t'$.

Для удобства будем считать, что наш процесс растет справа налево  
$$\ldots x_{t},~ x_{t-1},~ x_{t-2} \ldots$$
Так,  если цепь $\ldots x_{t}, x_{t-1}, x_{t-2} \ldots$ была порождена процессом порядка $2$,
то $$P(x_{t}| x_{t-1},x_{t-2}\ldots) = P(x_{t}|x_{t-1},x_{t-2})$$

\begin{definition} \emph{Марковская модель порядка $ m $} --- это вероятностная модель, описывающая марковский процесс порядка $m$. Параметрами модели являются множество вероятностных распределений переходов  $ A = \{a(q; x^{m})\}_{q \in S, x^{m} \in S^{m}}$, где $a(q; x^{m}) = P(q|x^{m})$, и начальное распределение $\pi = \pi(x^m)_{x^m \in S^m}$, где $\pi(x^m) = P(X_{0:m}=x^m)$.
\end{definition}

\begin{definition}
\textit{Контекстное дерево} --- это дерево, в котором каждая внутренняя вершина имеет $ |S| $ ребер, соответствующих состояниям из $S$, и метку, которая является конкатенацией метки на ее родителе и метки ребра от него. Метка в корне --- пустая строка. 
\end{definition}
\textit{Контекстом} состояния $ x_{t} $  будем называть любой префикс строки  $x_{t-1}, x_{t-2} \ldots$.
Контексты, соответствующие листьям контекстного дерева, будем называть \textit{главными контекстами} (иногда, когда речь будет идти только о листьях, слово <<главные>> будем опускать).

Множество переходов для Марковского процесса порядка $ m $ можно определить, как контекстное дерево глубины $ m+1 $, каждый лист которого содержит распределение $P(.~|~w)$, где $ w $ --- метка на листе.

Для того, чтобы по дереву определить распределение на следующем состоянии $ X_{t} $, достаточно из корня спуститься по ветке, вершины которой соответствуют контекстам этого состояния, $(x_{t-1}),\; (x_{t-1}x_{t-2}), \ldots$ . Лист на конце ветки и будет задавать распределение $ X_{t} $.

\begin{remark}
Метки на листьях контекстного дерева полностью определяют дерево.
\end{remark}

\begin{figure}[h!]\centering
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.38]{img/Context_trie.pdf}
	\centering
	\caption{ Контекстное дерево переходов Марковского процесса порядка 2 }
	\label{fig:context_trie}
\end{subfigure}
\hfil \hfil
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.38]{img/Prune_c_trie.png}
	\centering
	\caption{ Подрезанное контекстное дерево}
	\label{fig:prune_c_trie}
\end{subfigure}
\caption{Эквивалентные контекстные деревья. \\Серым подкрашены листья, ниже прямоугольниками обозначены распределения переходов.}
\label{fig:sample_tries}
\end{figure}

На рисунке \ref{fig:context_trie} изображен пример контекстного дерева для Марковского процесса порядка $ 2 $.
Можно заметить, что в этом примере, имея для некоторого состояния $x_{t}$ контекст  <<$1$>> , необходимость уточнять его (т.е. спускаться дальше к листу) отсутствует, т.к. распределение на контекстах  <<$10$>>  и  <<$11$>>  одно и тоже. 
Таким образом подрезанное дерево с рисунка \ref{fig:prune_c_trie} задает такие же распределения переходов как и дерево с рисунка \ref{fig:context_trie}. 
Однако второе контекстное дерево меньше (число главных контекстов меньше).
Но ни один Марковский процесс фиксированного порядка напрямую его использовать не может.

Определим процесс, который может иметь распределение переходов в виде дерева с рисунка \ref{fig:prune_c_trie}.

Пусть $\tau$ --- конечное контекстное дерево.
Для $s \in \tau$ будем обозначать через $ C(s) $ множество всех потомков, являющихся листами $\tau$. 
Для $s \notin \tau$, $C(s)$ --- лист $\tau$, являющийся префиксом  $s$ (можно заметить, что он существует и единственен).
\begin{definition}
\textit{Марковский процесс переменного порядка} (МППП) с максимально-возможным порядком $m$ --- это вероятностный процесс, распределения на состояниях которого задаются распределениями на листьях некоторого контекстного дерева $\tau$ глубины не более чем $m+1$.
\label{def:c_trie}
\end{definition}

\begin{definition}
Марковская модель переменного порядка (ММПП) с максимально-возможным порядком $m$ --- вероятностная модель, описывающая соответствующий процесс.
Параметрами модели являются множество распределений переходов на листьях некоторого контекстного дерева $\tau$ глубины не более чем $m+1$ и начальное вероятностное распределение на них (листьях).
\end{definition}

\begin{remark}
Распределения переходов на внутренних вершинах контекстного дерева определяются распределениями на листьях.
\begin{align}
P(q| s) &= \frac{\sum_{c \in C(s)} {a(q; c)P(c)}}{\sum_{q' \in S}\sum_{c \in C(s)} {a(q';c)P(c)}}
\label{formula:ap_p}
\end{align}
\end{remark}
\begin{remark}
Вероятности контекстов, соответствующих вершинам контекстного дерева, определяются вероятностным распределением на листьях.
\begin{align}
P(s) = \sum_{c \in C(s)}{P(c)}
\label{formula:p}
\end{align}
\end{remark}
\begin{remark}
МППП с максимально-возможным порядком $m$ есть обобщение всех Марковских процессов порядка меньше либо равного, чем $ m $.
\end{remark}

\subsection{Скрытые Марковские модели}
Представим, что состояния --- это какой-то скрытый признак/фактор (например, наличие или отсутствие связи белка и ДНК) цепи наблюдений $Y = \{y_{t}\}_{t \in Z_{+}}$. Для каждого наблюдения $y_{t}$ он не известен, однако именно он определяет распределение на $Y_{t}$.
Т.е. цепь $Y$ порождается из Марковской цепи $X = \{x_{t}\}_{t \in Z_{+}}$ путем покоординатного определения новой случайной величины $Y_{t}$ для каждого состояния $x_{t}$ согласно распределению $P(.|~x_{t})$.

\begin{definition}
Процесс, порождающий цепь по некоторому Марковскому процессу $X = \{x_{t}\}_{t \in Z_{+}}$ порядка $m$ и распределению $P(.|~x_{t})$, называется \textit{скрытым Марковским процессом порядка $m$}. 
$ X $ называеются \textit{скрытыми состоянияниями}, $Y$ --- \textit{наблюдениями}.
\end{definition}

\begin{definition}
\textit{Скрытая Марковская модель} (СММ) порядка $ m $ --- вероятностная модель, описывающая соответствующий процесс. Параметрами модели является $\Lambda=(A,\pi,B)$, где $A,\pi$ --- параметры скрытого процесса $X$ порядка $m$,  $ B = \{b(y; x)\}_{y \in R^{l}, x \in S}$ ---  множество распределений испусканий (где $ b(y; x) = P(y|x)$). 
\end{definition}

\begin{definition}
\textit{Скрытая Марковская модель переменного порядка} (СММПП) --- вероятностная модель, описывающая соответствующий процесс. Параметрами модели является $\Lambda=(A,\pi,B)$, где $A,\pi$ --- параметры скрытого процесса переменного порядка $X$ ,  $ B = \{b(y; x)\}_{y \in R^{l}, x \in S}$, где $ b(y; x) = P(y|x)$ ---  множество распределений испусканий. 
\end{definition}


\subsection{Обучение модели СММПП}
Задачу обучения скрытой Марковской модели переменного порядка можно сформулировать следующим образом: 
по цепи наблюдений $ Y = (y_{1}, ... y_{T}) $ найти параметры $\Lambda = (A,B,\pi)$ модели СММПП, которые бы минимизировали количество контекстов не сильно ухудшая правдоподобие модели по сравнению с правдоподобием модели на полном дереве (допустимое отклонение распределений регулирует параметр $ \varepsilon_{\text{prune}} $).
Правдоподобие модели с параметрами $\Lambda$ на выборке $Y$  --- это вероятность породить $Y$ из данной модели, $P(Y|\Lambda)$.
При обучении моделей правдоподобие считается на обучающей выборке.

В листинге \ref{alg} схематично представлен алгоритм обучения СММПП. Описание основных шагов: инициализация, EM-алгоритм, подрезание дерева --- приведено далее.

Конкатенацию строк $a$ и $b$ будем обозначать $ab$.
За $\pi(s)$, где $s \in \tau$, будем обозначать продолжение $\pi$ на все дерево (формула \ref{formula:p}).
Общее распределение на контекстах будем обозначать параметром $\rho(c)\defeq P(c)$.
\\

\begin{algorithm}[H]
 \KwData{
 \\$Y$,  // наблюдения
 \\$ m $, $ \varepsilon_{\textit{EM}} $, $ \varepsilon_{\textit{prune}} $  
 \\//параметры обучения: максимальная длина контекста, 
 \\//порог для остановки EM, порог для обрезания дерева}
 \KwResult{$\Lambda$  // параметры СММПП}
 \textit{
 $\Lambda$ = Инициализация($Y$, $m$)
 }\;
 // полное контекстное дерево\\
 \While{контекстное дерево уменьшается}{
 	\textit{
 	$\Lambda$ = EM($Y$, $\Lambda$, $ \varepsilon_{\textit{EM}} $)}\; 
 	// максимизируем правдоподобие модели на наблюдениях 
 	\\//при фиксированной структуре дерева
	\\\textit{
	$\Lambda$ = Подрезание($\Lambda$, $ \varepsilon_{\textit{prune}} $)}\; 
	// подрезаем дерево, если обученные распределения при этом несильно
	\\// изменяются
 }
 \caption{Схема обучения СММПП}
 \label{alg}
\end{algorithm}


\subsubsection{Инициализация}
Начальное контекстное дерево является полным $|S|$-нарным деревом глубины $m+1$ (соответствеут CMM порядка $m$).

В качестве начальных распределений переходов и параметров испусканий берутся оценки этих величин на цепи состояний, полученной алгоритмом $k$-means ($k=|S|$) по цепи наблюдений $Y$. \footnote{В общем случае, EM-алгоритм допускает случайную инициализацию.}

\subsubsection{EM (Expectation–Maximization algorithm)}
Оценки параметров проводятся подобно алгоритму Баума-Велша для СММ \cite{Rabiner1989}.
\begin{enumerate}
\item E-шаг (Expectation)

Введем дополнительный параметр $\alpha$
$$ \alpha_{t}(c) \defeq P(y_{0}^{t}, c(x_{t})=c| \Lambda)$$
$\alpha_{t}(c)$ --- вероятность породить первые $t+1$ наблюдений равными $y_{0}^{t}$, имея главным контекстом  скрытого состояния $x_{t}$ контекст $ c $, из модели СММПП с параметрами $\Lambda$.
\begin{align}
\alpha_{0}(c) &= \pi(c)b(y_{0}; c[0]) \nonumber \\
\alpha_{t+1}(c) &= \sum_{q \in S, c'=C(cq)}{\alpha_{t}(c')a(c[0];c')b(y_{t+1}; c[0])}
\label{formula:alpha}
\end{align}
Если $c'$ оказался внутренним листом дерева, то величина $a(c[0];c')$ считается по формуле \ref{formula:ap_p} c распределением на листьях равным $\pi$, распределением переходов равным $A$.

Введем дополнительный параметр $\beta$
$$ \beta_{t}(c) \defeq P(y_{t+1}^{T}| c(x_{t})=c, \Lambda))$$
$\beta_{t}(c)$ --- вероятность того, что последние $T-t$ наблюдений цепи длины $T$, порожденной из модели СММПП с параметрами $\Lambda$, в которой главный контекст скрытого состояния $x_{t}$ является $ c $, совпадают с $y_{t+1}^{T}$.
\begin{align}
\beta_{T}(c) &= 1 \nonumber \\
\beta_{t}(c) &= \sum_{q \in S, c'=C(qc)}{a(q;c)b(y_{t+1}, c'[0])\beta_{t+1}(c')}
\label{formula:beta}
\end{align}

Введем дополнительный параметр $\gamma$
$$ \gamma_{t}(c) \defeq P(x_{t}=c|Y,\Lambda) $$ 
$\gamma_{t}(c)$ --- вероятность того, что породив цепь $Y$ моделью СММПП c параметрами $\Lambda$,
главный контекст скрытого состояния $ x_{t} $ является $c$.
\begin{align}
\gamma_{t}(c) \propto {\alpha_{t}(c)\beta_{t}(c)}
\label{formula:gamma}
\end{align}

\item M-шаг (Maximization)

На этом шаге алгоритм обновляет параметры модели, максимизируя правдоподобие при условии посчитанных величин $\alpha, \beta, \gamma$.

Для пересчета параметра $A$ введем параметр $\xi$
\begin{align*}
\xi_{t}(q;c) \defeq P(c(x_{t})=c, x_{t+1} = q| Y, \Lambda)
\end{align*}
$\xi_{t}(q;c)$ --- вероятность того, что породив цепь $Y$ моделью СММПП c параметрами $\Lambda$, 
главный контекст скрытого состояния $ x_{t} $ является $c$ и состояние $ x_{t+1} $ совпадает с $q$.
\begin{align}
\xi_{t}(q;c) \propto {\alpha_{t}(c)a(q;c)b(y_{t+1},q)\beta_{t+1}(qc)} 
\label{formula:xi}
\end{align}
Обновление $ A , \rho, \pi$:
\begin{align}
a(q; c) &\propto \sum_{t}{\xi_{t}(q,c)} 
\label{formula:a}
\\\rho(c) &\propto \sum_{t}{\gamma_{t}(c)}
\\\pi(c) &\propto \gamma_{0}(c)
\end{align}

Пересчет $ B $ зависит от принятого семейства моделей испусканий и производится с помощью $ \gamma $ в точности также, как и в алгоритме Баума-Велша.
В случае распределения Пуассона
$b(.~|~q) \sim \textit{Poisson}(\lambda_{q})$ 
пересчет параметров происходит следующим образом:
\begin{align}
\lambda_{q} = \frac{\sum_{c}\sum_{t}{\gamma_{t}(c)I[c[0]=q]y_{t}}}{\sum_{c}\sum_{t}{\gamma_{t}(c)I[c[0]=q]}}
\end{align}
\end{enumerate}
EM-алгоритм запускает поочередно E-шаг и M-шаг, пока правдоподобие с предыдущей итерации отличается от правдоподобия с текущей итерации более, чем на $ \varepsilon_{\textit{EM}}$, т.е. пока итерация дает значимый прирост правдоподобия
\begin{align}
P(Y| \Lambda) = \sum_{c \in C}\alpha_{T}(c)
\end{align}

\begin{remark} При пересчете вероятности могут очень близко подходить к нулю, что отрицательно влияет на точность расчета. Для избежания этой проблемы все расчеты проводятся не с вероятностями, а с их логарифмами.
\end{remark}

\begin{remark} EM-алгоритм следует запускать несколько раз, т.к. он может <<застревать>> в локальных максимумах функции правдоподобия.
\end{remark}

\subsubsection{Подрезание дерева} 
Если существует внутренний лист контекстного дерева $ s $ такой, что 
\begin{align}
\forall q \in S \;\; P(sq)\textit{KL}(sq, s) < \varepsilon_{\textit{prune}} 
\end{align}
(дети не уточняют родителя), то $ s $ становится листом, а все его потомки обрезаются, где
\begin{align}
\textit{KL}(u, w) &= \sum_{q' \in S} P(q'|u) \log\frac{P(q'|u)}{P(q'|w)}\\
\end{align}
расстояния Кульбака-Лейблера для апостериорных распределений.

Если таких листьев не существует, алгоритм заканчивает работу.

$P(s), P(q|s), \text{ где } s \in \tau$ (и, как частный случай, новые $\rho$, $\pi$, $ A $) считаются по формулам \ref{formula:p}, \ref{formula:ap_p}, соответственно (по еще неподрезанному $\tau$).

\subsection{Обучение на нескольких выборках}
В случае пропусков в наблюдениях (связанных, например, с отсутствием данных), обучение модели может проходить на множестве из нескольких цельных кусков наблюдений.
Т.е. на вход алгоритма будет подаваться не одна выборка $Y$, а                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              $ N $ выборок $ \{Y^{1} \ldots Y^{N}\}$, подчиненных единому скрытому Марковском процессу переменного порядка.

Для применения вышеописанного алгоритма для обучения СММПП на нескольких выборках были внесены изменения в E-шаг и M-шаг.
\\
\begin{enumerate}
\item E-шаг

Дополнительные параметры $\alpha^{d}, \beta^{d}, \gamma^{d}, \xi^{d}$ пересчитываются отдельно на каждой выборке $d \in \{1, \ldots, N\}$ по формулам
\ref{formula:alpha}, \ref{formula:beta}, \ref{formula:gamma}, \ref{formula:xi}, соответственно.
\\
Общая $\gamma$ --- конкатенация $\gamma^{d}$.
\begin{align}
\gamma = [\gamma^{1}, \ldots ,\gamma^{N}] 
\end{align}
\item M-шаг
\begin{align}
a(q; c) &\propto \sum_{d}{\sum_{t}{\xi^{d}_{t}(q;c)}} 
\end{align}
\begin{align}
P(\{Y^{1} \ldots Y^{N}\}|\Lambda) &= \prod_{d}{P(Y^{d}|\Lambda)}
\end{align}

\end{enumerate}

\subsection{Сравнение}
\subsubsection*{Критерий Акаике}
Чем больше параметров у модели, тем лучше она подстраивается под данные, и тем проще переобучается. 
Поэтому, при сравнении моделей, обученных на одних и тех же данных, со схожим правдоподобием, предпочтительней будет та, которая проще. 
Конкретную величину, которую следует сравнивать для моделей, обученных на одинаковых данных, предлагает критерий Акаике (AIC)
\begin{align}
AIC = 2k-2\log{L}
\end{align}
где $ k $ --- число степеней свободы или число параметров модели, $ L $ --- максимальное правдоподобие модели на заданной выборке. Чем $AIC$ меньше, тем модель лучше. 

Число параметров для СММПП с $ n $ скрытыми состояниями, $ l $ контекстами, и Пуассоновскими испусканиями 
\begin{align}
k &= [\text{количество степеней свободы} \; A ] \nonumber
+ [\text{количество степеней свободы} \; B ] \nonumber
\\&+ [\text{количество степеней свободы} \; \pi ] \nonumber
\\ &= l(n-1)\;+\;n\;+\;(l-1) \nonumber\\&= nl + n - 1
\\ 
\text{При } n=2, k &= 2l + 1 \nonumber
\end{align}

Для СММ порядка $m$, $l=2^m$, поэтому $k = 2^{m+1}+1$.

\subsubsection*{FDR, FNR} 
Пусть гипотеза $\textit{H0}$ соответствует состоянию <<$0$>> (отсутствие взаимосвязи c белком), $\textit{H1}$ --- отвержение $\textit{H0}$.
Тогда ошибки первого, второго рода характеризуются величинами $\textit{FDR}$ --- математическое ожидание доли ложных единиц среди всех предсказанных единиц (false discovery rate),
$\textit{FNR}$ --- математическое ожидание доли ложных нулей среди всех предсказанных нулей  (false non-discovery rate) \cite{Sun2009}.
\begin{align}
\textit{FDR} = \mathbb{E}\frac{\textit{FP}}{\textit{P}}, 
~~~\textit{FNR} = \mathbb{E}\frac{\textit{FN}}{\textit{N}}
\end{align}
где $\textit{FP}$ (False Positive) --- количество неправильно идентифицированных единиц (количество состояний $0$, предсказанных как $1$), $\textit{P}$ (Positive) --- количество предсказанных единиц, $\textit{FN}$ (False Negative) --- количество неправильно идентифицированных нулей, $\textit{N}$ (Negative) --- количество предсказанных нулей. 

Сами величины $\textit{FDR}$, $\textit{FNR}$ напрямую оценить трудно, поэтому далее будем рассматривать их верхние оценки $\textit{mFDR}$ (marginal false discovery rate), $\textit{mFNR}$ (marginal false non-discovery rate).
\begin{align}
\textit{mFDR} = \frac{\mathbb{E}\textit{FP}}{\mathbb{E} \textit{P}}, 
~~~\textit{mFNR} = \frac{\mathbb{E}\textit{FN}}{\mathbb{E} \textit{N}}
\end{align}

Оценки $\hat{\textit{mFDR}}$, $\hat{\textit{mFNR}}$:
\begin{align}
\hat{\textit{mFDR}} = \frac{\sum_{t}{I[x_t]P(x_t=0)}}{\sum_{t}{I[x_t]}}
\label{formula:est_mFDR}
\end{align}
\begin{align}
\hat{\textit{mFNDR}} = \frac{\sum_{t}{I[x_t=0]P(x_t=1)}}{\sum_{t}{I[x_t=0]}}
\label{formula:est_mFNR}
\end{align}

Контроль $\textit{mFDR}$ будем осуществлять с помощью статистики $\textit{LIS}$, как это делают в работе \cite{Sun2009}. 
Для контроля $\textit{mFDR}$ величиной $\alpha$, состояние <<$1$>> присваивается позициям, соответствующим первым $ k $ позициям в отсортированном по убыванию списке величин $\textit{LIS}_{t}$, где
$\textit{LIS}_{t} = P(x_t=0| \text{взаимосвязь есть}) = I[x_t=0]P(x_t=1)$ --- (local index of significance),
\begin{align}
k = max\{i: \frac{1}{i}\sum_{t=0}^{i}{\textit{LIS}_{t}} < \alpha\}
\end{align}

\section{Реализация}
Общий алгоритм обучения скрытой Марковской модели переменного порядка был реализован на языке программирования Python версии 3.4.
 
Python является выразительным, но местами медленным языком программирования, поэтому критические по производительности места (E-шаг) были перенесены на Cython. Язык Cython --- расширение языка Python, транслирующее код в язык Си. Cython поддерживат опциональную типизацию и имеет эффективный интерфейс для работы с массивами NumPy.

С использованием библиотеки Joblib было распараллелено выполнение E-шага на нескольких выборках по потокам. Для эффективной работы с матрицами были использованы библиотеки NumPy, SciPy. Для отрисовки деревьев использовалась библиотека Pygraphviz. Все графики строились с помощью библиотеки Matplotlib.

Проект доступен по следующей ссылке: https://github.com/atanna/hmm


\section{Применение}
\subsection{Применение к симулированным данным}
Проверка работы алгоритма обучения происходила
в несколько этапов:
\begin{enumerate}
\item
генерация параметров $\Lambda$ начальной модели СММПП;
\item
порождение нескольких выборок $ Y $ из заданной модели;
\item
нахождение новых параметров $\hat{\Lambda}$ путем обучения модели на порожденных выборках;
\item
сравнение полученных параметров $\hat{\Lambda}$ с реальными $\Lambda$,
подсчет абсолютного среднего отклонения параметров реальной модели от предсказанных параметров. 
\end{enumerate}

Ниже проиллюстрирована работа алгоритма на простых моделях: Пуассоновская смесь (СММ нулевого порядка) и СММ (СММ первого порядка). Также проиллюстрирован более интересный случай: СММПП, не являющейся СММ фиксированного порядка.

Для каждого теста было сгенерировано по $100$ выборок длиной $5000$.
Значения параметров алгоритма обучения были выбраны следующими: максимально-возможный порядок $m=4$, порог для обрезания $ \varepsilon_{\textit{prune}} = 0.007$, порог для остановки EM $\varepsilon_{\textit{EM}} =  0.01 $ 

Были посчитаны абсолютное среднее отклонение (MAE --- Mean Absolute Error) полученных распределений переходов от реальных распределений, отклонение параметров Пуассоновского испускания $\lambda$ от реальных, оценки $\hat{\textit{mFDR}}$ ,  $\hat{\textit{mFNR}}$ (формулы \ref{formula:est_mFDR}, \ref{formula:est_mFNR}, соответственно).

Средние значения этих величин, полученных обучением модели на разных выборках при фиксированной начальной модели, показаны в соответствующих таблицах (\ref{table_mixture}, \ref{table_hmm1}, \ref{table_vlhmm}).

\subsubsection{Пуассоновская смесь}
Модель смеси была выбрана с параметрами переходов, изображенных контекстным деревом на рисунке \ref{fig:sample_mixture_real_trie} и параметрами испусканий
$$B = \{\textit{Poisson}(\lambda=2), \textit{Poisson}(\lambda=10)\}$$.

Сравнение полученных в ходе обучения параметров с реальными, $\hat{\textit{mFDR}}$, $\hat{\textit{mFNR}}$ показаны в таблице \ref{table_mixture}.
Пример предсказанного дерева изображен на рисунке \ref{fig:sample_mixture_predicted_trie}.
\begin{center}
    \begin{tabular}{ |l|*{4}{m{2cm}|} }
     \hline
     & $\textit{MAE}(A, \hat{A})$ & $\textit{MAE}(\lambda, \hat{\lambda})$ & $\hat{\textit{mFDR}}$ & $\hat{\textit{mFNR}}$
     \\ \hline
     $\textit{Среднее по тестам}$ & $0.07$ & $0.21$ & $0.01$ & $0.02$
     \\ \hline
    \end{tabular}
    \label{table_mixture}
\end{center}
\begin{figure}[h!]\centering
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.50]{img/sample_mixture/real_trie_.png}
	\centering
	\caption{ Реальное дерево }
	\label{fig:sample_mixture_real_trie}
	
\end{subfigure}
\hfil \hfil%раздвигаем боксы по горизонтали
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.50]{img/sample_mixture/predicted_trie.png}
	\centering
	\caption{ Предсказанное дерево }
	\label{fig:sample_mixture_predicted_trie}
\end{subfigure}
\caption{ Пуассоновская смесь }
\label{fig:sample_mixture}
\end{figure}

\subsubsection{СММ}
Модель СММ была выбрана с параметрами переходов, изображенных контекстным деревом на рисунке \ref{fig:sample_hmm1_real_trie} и параметрами испусканий
$$B = \{\textit{Poisson}(\lambda=1), \textit{Poisson}(\lambda=8)\}$$.

Сравнение полученных в ходе обучения параметров с реальными, $\hat{\textit{mFDR}}$, $\hat{\textit{mFNR}}$ показаны в таблице \ref{table_hmm1}.
Пример предсказанного дерева изображен на рисунке \ref{fig:sample_hmm1_predicted_trie}.
\begin{center}
    \begin{tabular}{ |l|*{4}{m{2cm}|} }
     \hline
     & $\textit{MAE}(A, \hat{A})$ & $\textit{MAE}(\lambda, \hat{\lambda})$ & $\hat{\textit{mFDR}}$ & $\hat{\textit{mFNR}}$
     \\ \hline
     $\textit{Среднее по тестам}$ & $0.09$ & $0.21$ & $0.02$ & $0.02$
     \\ \hline
    \end{tabular}
    \label{table_hmm1}
\end{center}

\begin{figure}[h!]\centering
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.35]{img/sample_hmm1/real_trie_.png}
	\centering
	\caption{ Реальное дерево }
	\label{fig:sample_hmm1_real_trie}
\end{subfigure}
\hfil \hfil%раздвигаем боксы по горизонтали
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.35]{img/sample_hmm1/predicted_trie.png}
	\centering
	\caption{ Предсказанное дерево }
	\label{fig:sample_hmm1_predicted_trie}
\end{subfigure}
\begin{subfigure}[b]{0.8 \textwidth}
	\includegraphics[scale=0.38]{img/sample_hmm1/plot_.png}
	\centering
	\caption{ График обучения }
	\label{fig:sample_hmm1_log_likelihood}
\end{subfigure}
\caption{ СММ }
\label{fig:sample_hmm1}
\end{figure}

На рисунке \ref{fig:sample_hmm1_log_likelihood} изображен график обучения. Каждая EM-часть выделена контуром, сверху которого написано число контекстов на момент обучения, снизу количество итераций в этой части и параметры распределения испусканий, полученных на последней итерации, внутри --- график логарифма правдоподобия по итерациям EM. 
На такой схеме видно, как сначала алгоритм 6 итераций EM обучался на 16 контекстах, после чего дерево подрезалось до 2 контекстов. Следующему EM не удалось значимо увеличить правдоподобие модели, поэтому на третей итерации он закончил работу. Далее дерево не удалось подрезать, поэтому весь алгоритм закончил свою работу (это видно из отсутствия следующего контура под график ЕM).

\subsubsection{СММПП, не являющаяся СММ фиксированного порядка}
Модель СММПП была выбрана с параметрами переходов, изображенных контекстным деревом на рисунке \ref{fig:sample_vlhmm_real_trie} и параметрами испусканий
$$B = \{\textit{Poisson}(\lambda=3), \textit{Poisson}(\lambda=15)\}$$.

Сравнение полученных в ходе обучения параметров с реальными,$\hat{\textit{mFDR}}$, $\hat{\textit{mFNR}}$ показаны в таблице \ref{table_vlhmm}.
Пример предсказанного дерева изображен на рисунке \ref{fig:sample_vlhmm_predicted_trie}.
На рисунке \ref{fig:sample_vlhmm_log_likelihood} представлен график обучения модели на одном из тестов.
\begin{center}
    \begin{tabular}{ |l|*{4}{m{2cm}|} }
     \hline
     & $\textit{MAE}(A, \hat{A})$ & $\textit{MAE}(\lambda, \hat{\lambda})$ & $\hat{\textit{mFDR}}$ & $\hat{\textit{mFNR}}$
     \\ \hline
     $\textit{Среднее по тестам}$ & $0.11$ & $0.20$ & $0.02$ &  $0.02$
     \\ \hline
    \end{tabular}
    \label{table_vlhmm}
\end{center}

\begin{figure}[h!]\centering
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.3]{img/sample/real_trie_.png}
	\centering
	\caption{ Реальное дерево }
	\label{fig:sample_vlhmm_real_trie}
	
\end{subfigure}
\hfil \hfil%раздвигаем боксы по горизонтали
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.3]{img/sample/predicted_trie.png}
	\centering
	\caption{ Предсказанное дерево }
	\label{fig:sample_vlhmm_predicted_trie}
\end{subfigure}
\begin{subfigure}[b]{0.8 \textwidth}
	\includegraphics[scale=0.38]{img/sample/plot_.png}
	\centering
	\caption{ График обучения }
	\label{fig:sample_vlhmm_log_likelihood}
\end{subfigure}
\caption{ СММПП, не являющаяся СММ фиксированного порядка }
\label{fig:sample_vlhmm}
\end{figure}

\subsection{Применение к реальным данным}
Для оценки модели на реальных данных использовались данные из проекта ENCODE (ENCyclopedia of DNA Elements).
В качестве изучаемого белка рассматривался гистон H3 с ацетилированным лизином в 27-й позиции. Исследуемые клетки --- эмбриональные стволовые клетки человека \cite{ENCODE}.
Размер окна был выбран равным 200 п.н.

В качестве выборок брались ненулевые участки массива, полученного после деления результата эксперимента ChIP-seq на окна.  

Ниже приведены результаты обучения на данных четвертой хромосомы (сумма длин обучающих выборок $\sim 10^5$).

Параметры обучения стояли следующими:
$m = 5$, $\varepsilon_{\textit{prune}} = 0.04$, $\varepsilon_{\textit{em}} = 0.05$

Из графика обучения (рис. \ref{fig:log_likelihood}) видно, как сначала алгоритм 12 итераций EM обучался на 32 контекстах, потом подрезал дерево до 5 контекстов. После чего ни обучение, ни подрезание не дало результатов, поэтому, алгоритм закончил работу.

Полученное контекстное дерево переходов для скрытого слоя состояний, отвечающих за ДНК-белковую связь проиллюстрировано на рисунке \ref{fig:real_trie}. Из него видно каким образом наличие взаимодействия с белком в фиксированном окне генома определяется взаимодействиями в предшествующих окнах.

\begin{figure}[h!]\centering
\begin{subfigure}[b]{0.49 \textwidth}
	\includegraphics[scale=0.47]{img/real/plot_.png}
	\centering
	\caption{ График обучения }
	\label{fig:log_likelihood}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32 \textwidth}
	\includegraphics[scale=0.29]{img/real/predicted_trie.png}
	\centering
	\caption{ Контекстноe дерево }
	\label{fig:real_trie}
\end{subfigure}
\caption{СММПП на реальных данных}
\label{fig:real}
\end{figure}

\begin{figure}[h!]\centering
\begin{subfigure}[b]{0.32 \textwidth}
	\includegraphics[scale=0.28]{img/real/log_p.png}
	\centering
	\caption{ Сравнение логарифма правдоподобия}
	\label{fig:real_comp_log_p}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32 \textwidth}
	\includegraphics[scale=0.28]{img/real/aic.png}
	\centering
	\caption{ Сравнение критерия Акаике }
	\label{fig:real_comp_aic}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.32 \textwidth}
	\includegraphics[scale=0.28]{img/real/time.png}
	\centering
	\caption{ Сравнение времени обучения }
	\label{fig:real_comp_time}
\end{subfigure}
\caption{ Сравнение моделей СММПП, СММ5 (СММ 5-го порядка, соответствует дереву, с которого начиналось обучение СММПП), СММ (СММ 1-го порядка, именно его чаще всего используют для анализа данных ChIP-seq) }
\label{fig:real_comp}
\end{figure}

Ниже представлено сравнение логарифма правдоподобия (рис. \ref{fig:real_comp_log_p}), критерия Акаике (рис. \ref{fig:real_comp_aic}) и времени обучения (рис. \ref{fig:real_comp_time}) для моделей СММПП, СММ5 и СММ.

По критерию Акаике (рис. \ref{fig:real_comp_aic}) выигрывает СММПП (напомним, что данный критерий, чем меньше, тем лучше).

СММ5 имеет лучшее среди этих трех моделей правдоподобие (рис. \ref{fig:real_comp_log_p}), однако ее губит большое количество параметров. 
СММ имеет меньшее среди данных моделей количество параметров, однако ее правдоподобие совсем невелико.
 
Время обучения СММПП (рис. \ref{fig:real_trie}) дает схожий результат с СММ5, немного ей уступая. СММ, в силу простоты структуры, обучается быстрее всех.


\section*{Заключение}
В ходе работы были решены поставленные задачи:
\begin{enumerate}
\item
реализована СММПП, подходящая под данные ChIP-seq;
\item
проведен анализ эффективности работы СММПП на
синтетических данных; 
\item
проведено сравнение СММПП с СММ порядка 1 и СММ порядка 5 на данных проекта ENCODE, согласно критерию Акаике СММПП является более подходящей моделью.
\end{enumerate}

\bibliographystyle{plain}
\bibliography{diploma.bib}
\end{document}
